{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b184ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have pymc3 installed on a conda distribution\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import theano.tensor.nnet as nnet\n",
    "import theano.tensor.signal.conv\n",
    "import theano\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89191d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pip (3x as slow though):\n",
    "# import aesara\n",
    "# import pytensor\n",
    "# import pytensor.tensor as tt  # it might not always find the conv sub function\n",
    "# import aesara.tensor.nnet as nnet\n",
    "# import aesara.tensor.signal.conv\n",
    "# import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad9621",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d464f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "series = pd.read_csv('data_2.csv', header=0, index_col=0, parse_dates=True)\n",
    "\n",
    "# Time frame\n",
    "start = '2022-11-7'\n",
    "end = '2022-11-15'\n",
    "\n",
    "series = series[start:end]\n",
    "\n",
    "# Set all nan-values to zero\n",
    "series['units_raw'] = series['units_raw'].fillna(0)\n",
    "series['bolus'] = series['bolus'].fillna(0)\n",
    "series['basal'] = series['basal'].fillna(0)\n",
    "\n",
    "# Custom series\n",
    "cgm_norm = series['cgm']  \n",
    "insulin_norm = series['insulin']\n",
    "basal_norm = series['basal']\n",
    "bolus_norm = series['bolus']\n",
    "units_raw = series['units_raw']\n",
    "heart_rate = series['heart_rate']\n",
    "\n",
    "# Creating a figure with 3 subplots (arranged vertically)\n",
    "fig, axs = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "# Plot the cgm_norm series on the first subplot\n",
    "axs[0].plot(cgm_norm.index, cgm_norm, marker='x', linestyle='None', label='CGM', color='g') \n",
    "axs[0].fill_between(cgm_norm.index, 3, 10, color='lightgreen', zorder=-1, alpha=0.5)\n",
    "axs[0].set_ylabel('Glucose (mmol)')\n",
    "axs[0].set_title('Measured CGM values')\n",
    "\n",
    "# Plot 2 - insulin_norm on the second subplot\n",
    "axs[1].plot(bolus_norm.index, bolus_norm, label='Concentration', color='b', linewidth=2)\n",
    "axs[1].plot(units_raw, label='Raw units', color='m', linewidth=2)\n",
    "axs[1].set_ylabel('Insulin (U)')\n",
    "axs[1].set_title('Bolus')\n",
    "\n",
    "# Plot 3 - Basal rate\n",
    "axs[2].plot(basal_norm.index, basal_norm, label='Concentration', color='b', linewidth=1)\n",
    "axs[2].set_ylabel('Insulin (U)')\n",
    "axs[2].set_title('Basal concentration')\n",
    "\n",
    "# # Plot 4 - Units on the third subplot\n",
    "# axs[3].plot(heart_rate.index, heart_rate, label='Heart Rate', color='c', linewidth=1)\n",
    "# axs[3].set_ylabel('BPM')\n",
    "# axs[3].set_xlabel('Time')\n",
    "# axs[3].set_title('Recorded heart rate')\n",
    "\n",
    "# Adding labels and legends to all subplots\n",
    "for ax in axs:\n",
    "    ax.set_xlim([pd.to_datetime(start), pd.to_datetime(end)])\n",
    "    ax.legend(loc='upper left')   \n",
    "\n",
    "# Day lines\n",
    "for i in range(0, len(series.index)):\n",
    "    if series.index[i].hour == 0 and series.index[i].minute == 0:\n",
    "        axs[0].axvline(x=series.index[i], color='grey', linestyle='--')\n",
    "        axs[1].axvline(x=series.index[i], color='grey', linestyle='--')\n",
    "        axs[2].axvline(x=series.index[i], color='grey', linestyle='--')\n",
    "        # axs[3].axvline(x=series.index[i], color='grey', linestyle='--')\n",
    "\n",
    "# Show the plot\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['axes.edgecolor'] = 'grey'\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "plt.rcParams['grid.color'] = 'grey'\n",
    "plt.rcParams['grid.linestyle'] = '--'\n",
    "plt.rcParams['grid.linewidth'] = 0.5\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f875e39",
   "metadata": {},
   "source": [
    "# Down-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb92ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data resolution: how much we are downsampling our data. \n",
    "data_resolution = 30\n",
    "\n",
    "# Downsample data\n",
    "cgm_norm_15min = cgm_norm.resample(str(data_resolution) + 'min').mean()\n",
    "insulin_norm_15min = insulin_norm.resample(str(data_resolution) + 'min').mean()\n",
    "bolus_norm_15min = bolus_norm.resample(str(data_resolution) + 'min').mean()\n",
    "basal_norm_15min = basal_norm.resample(str(data_resolution) + 'min').mean()\n",
    "\n",
    "# Delete the last item, since that one is always nan because of the resampling.\n",
    "cgm_norm_15min = cgm_norm_15min[:-1]\n",
    "insulin_norm_15min = insulin_norm_15min[:-1]\n",
    "bolus_norm_15min = bolus_norm_15min[:-1]\n",
    "basal_norm_15min = basal_norm_15min[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7197d",
   "metadata": {},
   "source": [
    "# Single fit horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ecfd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the horizon length\n",
    "horizon_minutes = 1790\n",
    "horizon = int(horizon_minutes / data_resolution)  # Adjust for your data resolution\n",
    "\n",
    "# Extend the time series for the horizon\n",
    "train_size = len(insulin_norm_15min) - horizon \n",
    "test_size = horizon\n",
    "\n",
    "extended_size = train_size + horizon\n",
    "integer_index = np.arange(extended_size) * data_resolution\n",
    "\n",
    "# Define training and testing variables\n",
    "cgm_train = cgm_norm_15min[:train_size]\n",
    "cgm_test = cgm_norm_15min[train_size:]\n",
    "bolus_train = bolus_norm_15min[:train_size]\n",
    "bolus_test = bolus_norm_15min[train_size:]\n",
    "\n",
    "print(cgm_test[-2], cgm_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1368dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(integer_index[:train_size], cgm_norm_15min[:train_size], label='Observed CGM', color='green', linewidth=2, marker='x')\n",
    "plt.plot(integer_index[train_size:], cgm_norm_15min[train_size:], label='PH CGM', color='green', alpha=0.5, marker='x')\n",
    "\n",
    "# Add vertical lines for train/test split and prediction horizon\n",
    "plt.axvline(x=train_size * data_resolution, color='r', linestyle='--', label='Test start', zorder=10)\n",
    "plt.axvline(x=(train_size + horizon - 1) * data_resolution, color='g', linestyle='--', label='Prediction Horizon', zorder=5)\n",
    "\n",
    "# Fill range\n",
    "plt.fill_between(integer_index, 3, 10, color='lightgreen', alpha=0.3)\n",
    "\n",
    "# Plot a vertical line at every begin of a new day\n",
    "for i in integer_index:\n",
    "    if (i * data_resolution) % (1440 * data_resolution) == 0:\n",
    "        plt.axvline(x=i, color='grey', linestyle='--')\n",
    "        \n",
    "plt.title('Prediction horizon')\n",
    "plt.legend()\n",
    "plt.xlabel('Minutes')\n",
    "plt.ylabel('Insulin (U)')\n",
    "plt.xlim(int(len(integer_index)) * data_resolution - 4500, min((int(len(integer_index)) * data_resolution + 20), (train_size + horizon) * data_resolution))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d9060",
   "metadata": {},
   "source": [
    "# Variables and activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42deb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calorie conversion to gram\n",
    "calorie_per_gram_per_macro = {\n",
    "    \"carb\": 4,\n",
    "    \"protein\": 4,\n",
    "    \"fat\": 9,\n",
    "}\n",
    "# Conversion rate:\n",
    "conversion_ratios = {\n",
    "    \"carb\":2.15,\n",
    "    \"protein\":0.75,\n",
    "    \"fat\":1.4\n",
    "}\n",
    "\n",
    "# Gram of carb to units of insulin ratio (g/U)\n",
    "ic_ratio = 11.1\n",
    "ip_ratio = 11.1\n",
    "if_ratio = 11.1\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "def normal_skew(units, mu=0.3, sigma=0.3, a=2, conversion_rate=conversion_ratios['carb'], scale=1):\n",
    "    '''\n",
    "    Additive effect of carbohydrates on blood glucose levels, modeled over time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    units :     NDArray[np.float32]\n",
    "                number of units of insulin to counter effect, based on the g/U ratio for protein\n",
    "    mu :        float\n",
    "                mean of the normal distribution\n",
    "    sigma :     float\n",
    "                standard deviation of the normal distribution\n",
    "    a :         float\n",
    "                shape parameter of the Weibull distribution\n",
    "    conversion_rate : float\n",
    "                conversion rate of protein to units of insulin, used to see relative effect against other macronutrients \n",
    "    scale :     float\n",
    "                scalar multiplicator \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    activation : NDArray[np.float32]\n",
    "                additive effect of protein on blood glucose levels, modeled over time in range from 0 to 1000 minutes.\n",
    "    '''\n",
    "    x = np.linspace(0, 5, 1000)\n",
    "    z = (x - mu) / sigma\n",
    "    pdf = (1 / (sigma * tt.sqrt(2 * np.pi))) * tt.exp(-z ** 2 / 2)\n",
    "    cdf = (1 + tt.erf(a * z / tt.sqrt(2)))\n",
    "    activation = units * conversion_rate * pdf * cdf * scale\n",
    "    return activation\n",
    "\n",
    "def theano_carbohydrate_activation(units, alpha=2.3, beta=1.1, conversion_rate=conversion_ratios['carb']):\n",
    "    '''\n",
    "    Additive effect of carbohydrates on blood glucose levels, modeled over time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    units :     NDArray[np.float32]\n",
    "                number of units of insulin to counter effect, based on the g/U ratio for carbs\n",
    "    alpha :     float\n",
    "                shape parameter of the Weibull distribution\n",
    "    beta :      float\n",
    "                scale parameter of the Weibull distribution\n",
    "    conversion_rate : float\n",
    "                conversion rate of carbs to units of insulin, used to see relative effect against other macronutrients \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    activation : NDArray[np.float32]\n",
    "                additive effect of carbohydrates on blood glucose levels, modeled over time in range from 0 to 1000 minutes.\n",
    "    '''\n",
    "    x = np.linspace(0, 10, 1000)\n",
    "    weibull = (alpha / beta) * (x / beta) ** (alpha - 1) * tt.exp(-(x / beta) ** alpha)\n",
    "    activation = units * conversion_rate * weibull\n",
    "    \n",
    "    # Downside flush\n",
    "    flush_scale = 0.3\n",
    "    flush_units = units\n",
    "    flush_mu = 1.4\n",
    "    flush_sigma = 0.3\n",
    "    flush_a = 1\n",
    "    \n",
    "    return activation - normal_skew(flush_units, mu=flush_mu, sigma=flush_sigma, scale=flush_scale, a=flush_a)\n",
    "\n",
    "\n",
    "def theano_protein_activation(units, mu=1.1, sigma=0.5 , a=1, conversion_rate=conversion_ratios['protein']):\n",
    "    '''\n",
    "    Additive effect of protein on blood glucose levels, modeled over time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    units :     NDArray[np.float32]\n",
    "                number of units of insulin to counter effect, based on the g/U ratio for protein\n",
    "    mu :        float\n",
    "                mean of the normal distribution\n",
    "    sigma :     float\n",
    "                standard deviation of the normal distribution\n",
    "    a :         float\n",
    "                shape parameter of the Weibull distribution\n",
    "    conversion_rate : float\n",
    "                conversion rate of protein to units of insulin, used to see relative effect against other macronutrients \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    activation : NDArray[np.float32]\n",
    "                additive effect of protein on blood glucose levels, modeled over time in range from 0 to 1000 minutes.\n",
    "    '''\n",
    "    x = np.linspace(0, 5, 1000)\n",
    "    z = (x - mu) / sigma\n",
    "    pdf = (1 / (sigma * tt.sqrt(2 * np.pi))) * tt.exp(-z ** 2 / 2)\n",
    "    cdf = (1 + tt.erf(a * z / tt.sqrt(2)))\n",
    "\n",
    "    # Multiply every gamma function with the number of units\n",
    "    activation = cdf * pdf * units * conversion_rate\n",
    "    \n",
    "    # Upside flush\n",
    "    flush_scale = 0.045\n",
    "    flush_units = units\n",
    "    flush_mu = 0.7\n",
    "    flush_sigma = 0.3\n",
    "    flush_a = 2\n",
    "    correct_up = normal_skew(flush_units, mu=flush_mu, sigma=flush_sigma, scale=flush_scale, a=flush_a)\n",
    "    \n",
    "    # Downside flush 2\n",
    "    flush2_scale = 0.01\n",
    "    flush2_units = units\n",
    "    flush2_mu = 0.45\n",
    "    flush2_sigma = 0.25\n",
    "    flush2_a = 2\n",
    "    correct_down = normal_skew(flush2_units, mu=flush2_mu, sigma=flush2_sigma, scale=flush2_scale, a=flush2_a)\n",
    "    \n",
    "    return activation + correct_up # - correct_down\n",
    "\n",
    "\n",
    "def theano_fat_activation(units, mu=1.3, sigma=0.7 , a=1, conversion_rate=conversion_ratios['fat']):\n",
    "    '''\n",
    "    Additive effect of fat on blood glucose levels, modeled over time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    units :     NDArray[np.float32]\n",
    "                number of units of insulin to counter effect, based on the g/U ratio for fat\n",
    "    mu :        float\n",
    "                mean of the normal distribution\n",
    "    sigma :     float\n",
    "                standard deviation of the normal distribution\n",
    "    a :         float\n",
    "                shape parameter of the Weibull distribution\n",
    "    conversion_rate : float\n",
    "                conversion rate of fat to units of insulin, used to see relative effect against other macronutrients \n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    activation : NDArray[np.float32]\n",
    "                additive effect of fat on blood glucose levels, modeled over time in range from 0 to 1000 minutes.\n",
    "    '''\n",
    "    x = np.linspace(0, 5, 1000)\n",
    "    z = (x - mu) / sigma\n",
    "    pdf = (1 / (sigma * tt.sqrt(2 * np.pi))) * tt.exp(-z ** 2 / 2)\n",
    "    cdf = (1 + tt.erf(a * z / tt.sqrt(2)))\n",
    "    \n",
    "    fat_units = units * conversion_rate\n",
    "    \n",
    "    carb_scale = 0.08\n",
    "    carb_units = units\n",
    "    carb_mu = 0.2\n",
    "    carb_sigma = 0.3\n",
    "    carb_a = 2\n",
    "    correct_down = normal_skew(carb_units, mu=carb_mu, sigma=carb_sigma, scale=carb_scale, a=carb_a)\n",
    "    \n",
    "    # Upside flush\n",
    "    flush_scale = 0.04\n",
    "    flush_units = units\n",
    "    flush_mu = 0.9\n",
    "    flush_sigma = 0.3\n",
    "    flush_a = 2\n",
    "    correct_up = normal_skew(flush_units, mu=flush_mu, sigma=flush_sigma, scale=flush_scale, a=flush_a)\n",
    "    \n",
    "    activation = fat_units * pdf * cdf \n",
    "    \n",
    "    return activation - correct_down + correct_up\n",
    "\n",
    "def theano_insulin_activation(units, sensitivity=1, alpha=2, rate=1.045):\n",
    "    x = np.linspace(0, 16, 1000)  # Change the range to hours (0 to 8 hours)\n",
    "    shifted_x = x - 12.28/60\n",
    "    shifted_x[shifted_x <= 0] = 1e-8  # Replace non-positive values with a small positive value\n",
    "    \n",
    "    gamma = tt.exp(tt.gammaln(alpha) - tt.log(rate) * alpha - rate * shifted_x + (alpha - 1) * tt.log(shifted_x))\n",
    "    \n",
    "    # Multiply every gamma function with the number of units\n",
    "    gamma = gamma * units * sensitivity\n",
    "\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b45402",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "#                        CONVOLUTION                      # \n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "def conv_activation(units, kernel):\n",
    "    \"\"\"\n",
    "    Perform the convolution using theano.tensor.nnet.conv2d.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    units : NDArray[np.float32]\n",
    "            number of units of insulin to counter effect, based on the g/U ratio\n",
    "    kernel : NDArray[np.float32]\n",
    "             kernel representing the activation function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    conv_result : NDArray[np.float32]\n",
    "                  result of the convolution\n",
    "    \"\"\"\n",
    "    # Reshape units and kernel tensors to meet the input requirements of conv2d\n",
    "    units = units.dimshuffle('x', 'x', 0, 'x')\n",
    "    kernel = kernel.dimshuffle('x', 'x', 0, 'x')\n",
    "\n",
    "    # Perform convolution\n",
    "    conv_result = pytensor.tensor.conv.conv2d(input=units, filters=kernel, border_mode='full')[0, 0, :, 0]\n",
    "\n",
    "    return conv_result\n",
    "\n",
    "\n",
    "def fourier_series(time, n_terms, amplitude, phase_shift, data_resolution, period=1440):\n",
    "    time_adjusted = time * data_resolution  # make the time periodical over 1440 minutes\n",
    "    result = 0\n",
    "    for i in range(n_terms):\n",
    "        result += amplitude[i] * (tt.sin(2 * np.pi * ((i+1) * (time_adjusted + phase_shift[i]) % period) / period) + 1) / 2\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "\n",
    "    # --------------- MEAL TIMING --------------------\n",
    "\n",
    "    # Meal availability fourier series\n",
    "    n_meal_terms = 6\n",
    "    meal_amplitude = pm.Uniform('meal_amplitude', lower=0, upper=0.2, shape=n_meal_terms)\n",
    "    meal_phase_shift = pm.Uniform('meal_phase_shift', lower=0, upper=1440, shape=n_meal_terms)\n",
    "    meal_prob = pm.Deterministic('mp', fourier_series(np.arange(extended_size), n_meal_terms, meal_amplitude, meal_phase_shift, data_resolution))\n",
    "    mt = pm.Bernoulli('mt', p=meal_prob, shape=extended_size)\n",
    "\n",
    "    \n",
    "    # --------------- MEAL SIZE --------------------\n",
    "\n",
    "    # Carb, protein, and fat calories per meal\n",
    "    n_cpm_terms = 4  # Number of sinusoids for cpm\n",
    "    cpm_amplitude = pm.Uniform('cpm_amplitude', lower=0, upper=100, shape=n_cpm_terms)  # assuming max meal size of 100 calories\n",
    "    cpm_phase_shift = pm.Uniform('cpm_phase_shift', lower=0, upper=1440, shape=n_cpm_terms)\n",
    "    cpm = pm.Deterministic('cpm', fourier_series(np.arange(extended_size), n_cpm_terms, cpm_amplitude, cpm_phase_shift, data_resolution))\n",
    "\n",
    "    # Multiply the cpm values with mt\n",
    "    cpm_binary = pm.Deterministic('cpmt', tt.switch(tt.eq(mt, 1), cpm, 0))\n",
    "    \n",
    "    \n",
    "    # --------------- DIET COMPOSITION --------------------\n",
    "\n",
    "    # Diet composition percentage logits\n",
    "    logit_c = pm.Normal('logit_C', mu=0.442, sigma=0.075)\n",
    "    logit_p = pm.Normal('logit_P', mu=0.147, sigma=0.04)\n",
    "    logit_f = pm.Normal('logit_F', mu=0.365, sigma=0.064)\n",
    "\n",
    "    # Apply softmax to obtain percentages summed to 1\n",
    "    softmax_logits = tt.special.softmax([logit_c, logit_p, logit_f], axis=-1)\n",
    "\n",
    "    # Percentages\n",
    "    perc_c = pm.Deterministic('%C', softmax_logits[0])\n",
    "    perc_p = pm.Deterministic('%P', softmax_logits[1])\n",
    "    perc_f = pm.Deterministic('%F', softmax_logits[2])\n",
    "    \n",
    "    # Diet composition in grams per meal\n",
    "    g_c = pm.Deterministic('g_C', cpm_binary * perc_c / calorie_per_gram_per_macro['carb'])\n",
    "    g_p = pm.Deterministic('g_P', cpm_binary * perc_p / calorie_per_gram_per_macro['protein'])\n",
    "    g_f = pm.Deterministic('g_F', cpm_binary * perc_f / calorie_per_gram_per_macro['fat'])\n",
    "\n",
    "    # Insulin required for each macronutrient (g/U)\n",
    "    ic = pm.Deterministic('IC', g_c / ic_ratio)\n",
    "    ip = pm.Deterministic('IP', g_p / ip_ratio)\n",
    "    if_ = pm.Deterministic('IF', g_f / if_ratio)\n",
    "\n",
    "\n",
    "    # --------------- POSITIVE CONVOLUTION --------------------\n",
    "\n",
    "    # Adjust the activation kernels to have a unit equal to 1\n",
    "    carb_kernel = theano_carbohydrate_activation(1, conversion_rate=conversion_ratios['carb'])[::data_resolution]\n",
    "    protein_kernel = theano_protein_activation(1, conversion_rate=conversion_ratios['protein'])[::data_resolution]\n",
    "    fat_kernel = theano_fat_activation(1, conversion_rate=conversion_ratios['fat'])[::data_resolution]\n",
    "\n",
    "    # Convert mt to float to be able to convolute\n",
    "    mt = mt.astype('float64')\n",
    "\n",
    "    # Convolution of meal availability with activation functions\n",
    "    conv_carb = pm.Deterministic('conv_carb', conv_activation(ic, carb_kernel))\n",
    "    conv_protein = pm.Deterministic('conv_protein', conv_activation(ip, protein_kernel))\n",
    "    conv_fat = pm.Deterministic('conv_fat', conv_activation(if_, fat_kernel))\n",
    "\n",
    "    # Total blood glucose level contribution from all macronutrients\n",
    "    total_activation = pm.Deterministic('total_activation', conv_carb + conv_protein + conv_fat)\n",
    "    \n",
    "    # -------------------- NEGATIVE CONVOLUTION --------------------\n",
    "    \n",
    "    # Meal availability fourier series\n",
    "    n_insulin_terms = 3\n",
    "    insulin_amplitude = pm.Uniform('insulin_amplitude', lower=0, upper=0.3, shape=n_insulin_terms)\n",
    "    insulin_phase_shift = pm.Uniform('insulin_phase_shift', lower=0, upper=1440, shape=n_insulin_terms)\n",
    "    insulin_prob = pm.Deterministic('ip', fourier_series(np.arange(extended_size), n_insulin_terms, insulin_amplitude, insulin_phase_shift, data_resolution))\n",
    "    it = pm.Bernoulli('it', p=insulin_prob, shape=extended_size)\n",
    "    \n",
    "    # Calories to units of insulin ratio\n",
    "    calorie_insulin_ratio = pm.HalfNormal('calorie_insulin_ratio', tau=1/14)\n",
    "    \n",
    "    upm = pm.Deterministic('upm', cpm / calorie_insulin_ratio)\n",
    "    \n",
    "    # Multiply the cpm values with mt\n",
    "    insulin_binary = pm.Deterministic('upmt', tt.switch(tt.eq(it, 1), upm, 0))\n",
    "    \n",
    "    # Create kernel\n",
    "    insulin_kernel = theano_insulin_activation(1)[::data_resolution]\n",
    "    bolus_insulin_conv = pm.Deterministic('conv_insulin', conv_activation(insulin_binary, insulin_kernel))\n",
    "    \n",
    "    insulin_sd = pm.Exponential('insulin_sigma', lam=1/0.5)\n",
    "    bolus_insulin = pm.Normal('bolus_insulin', mu=bolus_insulin_conv[:train_size], sigma=insulin_sd, observed=bolus_train)\n",
    "\n",
    "    # --------------- PASSIVE COMPONENT --------------------\n",
    "\n",
    "    # Basal glucose production\n",
    "    n_basal_terms = 1\n",
    "    basal_amplitude = pm.Uniform('basal_amplitude', lower=0, upper=1, shape=n_basal_terms)\n",
    "    basal_phase_shift = pm.Uniform('basal_phase_shift', lower=0, upper=1440, shape=n_basal_terms)\n",
    "\n",
    "    basal_offset = pm.Normal('basal_baseline', mu=3, sigma=1)\n",
    "    basal_active = pm.Deterministic('basal_active', fourier_series(np.arange(extended_size), n_basal_terms, basal_amplitude, basal_phase_shift, data_resolution) + basal_offset)    \n",
    "    total_basal = pm.ConstantData('total_basal', basal_norm_15min[:extended_size])\n",
    "\n",
    "    # --------------- COMBINING VARIABLES ---------------\n",
    "\n",
    "    # Calculate component effects\n",
    "    total_active = pm.Deterministic('total_active', total_activation[:extended_size] - bolus_insulin_conv[:extended_size])  # Total active component\n",
    "    total_passive = pm.Deterministic('total_passive', basal_active - total_basal)  # Total passive component\n",
    "\n",
    "    # Theoretical CGM readings\n",
    "    total_cgm = pm.Deterministic('cgm_est', total_active[:train_size] + total_passive[:train_size])\n",
    "\n",
    "    # Define the likelihood of the model\n",
    "    sigma = pm.Exponential('sigma', lam=1/0.5)\n",
    "    likelihood = pm.Normal('likelihood', mu=total_cgm, sigma=sigma, observed=cgm_train)\n",
    "\n",
    "    # --------------- SAMPLING ---------------\n",
    "\n",
    "    # Run the MCMC sampling\n",
    "    step = pm.NUTS(target_accept=0.95)\n",
    "    trace = pm.sample(draws=2000, tune=1000, chains=4, cores=4, step=step, return_inferencedata=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d6d2a",
   "metadata": {},
   "source": [
    "## Plotting macronutrient concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8e499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "# Define the macronutrients\n",
    "macronutrients = ['conv_carb', 'conv_protein', 'conv_fat']\n",
    "names = ['Carbs', 'Protein', 'Fats']\n",
    "colors = ['purple', 'green', 'orange']\n",
    "\n",
    "# For each macronutrient\n",
    "for i, macronutrient in enumerate(macronutrients):\n",
    "    # Calculate the median and percentiles\n",
    "    median = np.median(trace.posterior[macronutrient].values, axis=(0, 1))[:extended_size]\n",
    "    low_50, high_50 = np.percentile(trace.posterior[macronutrient].values, [25, 75], axis=(0, 1))[:extended_size]\n",
    "    low_75, high_75 = np.percentile(trace.posterior[macronutrient].values, [12.5, 87.5], axis=(0, 1))[:extended_size]\n",
    "    low_95, high_95 = np.percentile(trace.posterior[macronutrient].values, [2.5, 97.5], axis=(0, 1))[:extended_size]\n",
    "    \n",
    "    # Plot the median and percentiles\n",
    "    plt.fill_between(integer_index, low_50[:extended_size], high_50[:extended_size], color=colors[i], alpha=0.4)\n",
    "    plt.fill_between(integer_index, low_75[:extended_size], high_75[:extended_size], color=colors[i], alpha=0.3)\n",
    "    plt.fill_between(integer_index, low_95[:extended_size], high_95[:extended_size], color=colors[i], alpha=0.2)\n",
    "    plt.plot(integer_index, median, linewidth=5, label=names[i], color=colors[i])\n",
    "    \n",
    "# Lines\n",
    "plt.axhline(y=0, color='black', linewidth=1)\n",
    "plt.axvline(x=train_size * data_resolution, color='r', linestyle='-', label='Train/Test Split')\n",
    "# plt.axvline(x=(train_size + horizon) * data_resolution, color='g', linestyle='-', label='Prediction Horizon')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim(int(len(integer_index)) * data_resolution - 4500, int(len(integer_index)) * data_resolution + 20)\n",
    "plt.title('Convoluted macros')\n",
    "plt.xlabel('Time (minutes)')\n",
    "plt.ylabel('Glucose exursion (mmol/L)')\n",
    "\n",
    "# Plot a vertical line at every begin of a new day\n",
    "for i in integer_index:\n",
    "    if (i * data_resolution) % (1440 * data_resolution) == 0:\n",
    "        plt.axvline(x=i, color='grey', linestyle='--')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62d96ca",
   "metadata": {},
   "source": [
    "## Plotting insulin concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1392d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "insulin_sigma_samples = trace.posterior['insulin_sigma'].values\n",
    "conv_insulin_samples = trace.posterior['conv_insulin'].values\n",
    "\n",
    "# Calculate the mean of sigma_samples along the first two dimensions\n",
    "insulin_mean_sigma_samples = np.mean(insulin_sigma_samples, axis=(0, 1))\n",
    "\n",
    "# Generate noise with shape matching total_active (and total_passive)\n",
    "noise = np.random.normal(loc=0, scale=insulin_mean_sigma_samples, size=conv_insulin_samples.shape)\n",
    "\n",
    "# Extract basal_active values\n",
    "bolus_insulin_values = conv_insulin_samples + noise\n",
    "\n",
    "# Calculate the median and percentiles\n",
    "bolus_insulin_active_median = np.median(bolus_insulin_values, axis=(0, 1))[:extended_size]\n",
    "bolus_insulin_active_low_50, bolus_insulin_active_high_50 = np.percentile(bolus_insulin_values, [25, 75], axis=(0, 1))\n",
    "bolus_insulin_active_low_75, bolus_insulin_active_high_75 = np.percentile(bolus_insulin_values, [12.5, 87.5], axis=(0, 1))\n",
    "bolus_insulin_active_low_95, bolus_insulin_active_high_95 = np.percentile(bolus_insulin_values, [2.5, 97.5], axis=(0, 1))\n",
    "\n",
    "# Calculate the time index\n",
    "integer_index = np.arange(extended_size) * data_resolution\n",
    "\n",
    "# Create subplots\n",
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "# Plot the median and percentiles\n",
    "plt.fill_between(integer_index, bolus_insulin_active_low_50[:extended_size], bolus_insulin_active_high_50[:extended_size], color='red', alpha=0.6)\n",
    "plt.fill_between(integer_index, bolus_insulin_active_low_75[:extended_size], bolus_insulin_active_high_75[:extended_size], color='red', alpha=0.4)\n",
    "plt.fill_between(integer_index, bolus_insulin_active_low_95[:extended_size], bolus_insulin_active_high_95[:extended_size], color='red', alpha=0.2)\n",
    "\n",
    "# Plot the median line\n",
    "plt.plot(integer_index, bolus_insulin_active_median, linewidth=5, label='Posterior median', color='black')\n",
    "plt.plot(integer_index[:train_size], bolus_norm_15min[:train_size], linewidth=5, label='Observed', color='blue')\n",
    "plt.plot(integer_index[train_size:], bolus_norm_15min[train_size:], linewidth=5, color='blue', alpha=0.5)\n",
    "plt.axvline(x=train_size * data_resolution, color='r', linestyle='-', label='Train/Test Split')\n",
    "plt.axvline(x=(train_size + horizon) * data_resolution, color='g', linestyle='-')\n",
    "\n",
    "# Add legend to the plot\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim(int(len(integer_index)) * data_resolution - 4500, int(len(integer_index)) * data_resolution + 20)\n",
    "plt.title('Insulin')\n",
    "plt.xlabel('Time (minutes)')\n",
    "plt.ylabel('Insulin (U)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13072c",
   "metadata": {},
   "source": [
    "## Plotting final estimated CGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecce71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting values from the trace\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "sigma_samples = trace.posterior['sigma'].values\n",
    "total_active = trace.posterior[\"total_active\"].values\n",
    "total_passive = trace.posterior[\"total_passive\"].values\n",
    "\n",
    "# Calculate the mean of sigma_samples along the first two dimensions\n",
    "mean_sigma_samples = np.mean(sigma_samples, axis=(0, 1))\n",
    "\n",
    "# Generate noise with shape matching total_active (and total_passive)\n",
    "noise = np.random.normal(loc=0, scale=mean_sigma_samples, size=total_active.shape)\n",
    "\n",
    "# Add all components together\n",
    "net = total_active + total_passive + noise\n",
    "\n",
    "net_median = np.median(net, axis=(0, 1))\n",
    "low_50, high_50 = np.percentile(net, [25, 75], axis=0)\n",
    "low_75, high_75 = np.percentile(net, [12.5, 87.5], axis=0)\n",
    "low_95, high_95 = np.percentile(net, [2.5, 97.5], axis=0)\n",
    "\n",
    "# Calculate the time index\n",
    "integer_index = np.arange(extended_size) * data_resolution\n",
    "\n",
    "# Create subplots\n",
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "# # Subplot for glucose\n",
    "plt.fill_between(integer_index, np.mean(low_50, axis=0), np.mean(high_50, axis=0), color='red', alpha=0.6)\n",
    "plt.fill_between(integer_index, np.mean(low_75, axis=0), np.mean(high_75, axis=0), color='red', alpha=0.4)\n",
    "plt.fill_between(integer_index, np.mean(low_95, axis=0), np.mean(high_95, axis=0), color='red', alpha=0.2)\n",
    "plt.plot(integer_index[train_size:], cgm_norm_15min[train_size:extended_size], label='True CGM', linewidth=5, color='green', alpha=0.5, zorder=15, marker='x')\n",
    "plt.plot(integer_index[:train_size], cgm_train, label='Observed CGM', linewidth=5, color='green')\n",
    "plt.plot(integer_index, net_median, label='Posterior median', color='black', linewidth=5)\n",
    "\n",
    "# Lines\n",
    "plt.fill_between(integer_index, 3, 10, color='lightgreen', alpha=0.4, zorder=-1)\n",
    "plt.axvline(x=train_size * data_resolution, color='r', linestyle='-', label='Train/Test Split', linewidth=4)\n",
    "plt.axvline(x=(train_size + horizon) * data_resolution, color='g', linestyle='-')\n",
    "# axs[0].axhline(y=3, color='red', linestyle='--')\n",
    "# axs[0].axhline(y=10, color='red', linestyle='--')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(int(len(integer_index)) * data_resolution - 4500, int(len(integer_index)) * data_resolution + 20)\n",
    "# plt.xlim(int(len(integer_index)) * data_resolution - 6000, train_size * data_resolution)\n",
    "plt.ylim(2, 14)\n",
    "plt.title('Fitted and predicted glucose')\n",
    "plt.xlabel('Time (minutes)')\n",
    "plt.ylabel('mmol/L')\n",
    "\n",
    "for i in integer_index:\n",
    "    if (i * data_resolution) % (1440 * data_resolution) == 0:\n",
    "        plt.axvline(x=i, color='grey', linestyle='--')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406e2168",
   "metadata": {},
   "source": [
    "## Passive compartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f69582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "# Extract basal_active values\n",
    "basal_active_values = trace.posterior['basal_active'].values[:, :, :extended_size]\n",
    "\n",
    "# Calculate the median and percentiles\n",
    "basal_active_median = np.median(basal_active_values, axis=(0, 1))\n",
    "basal_active_low_50, basal_active_high_50 = np.percentile(basal_active_values, [25, 75], axis=(0, 1))\n",
    "basal_active_low_75, basal_active_high_75 = np.percentile(basal_active_values, [12.5, 87.5], axis=(0, 1))\n",
    "basal_active_low_95, basal_active_high_95 = np.percentile(basal_active_values, [2.5, 97.5], axis=(0, 1))\n",
    "\n",
    "# Plot the median and percentiles\n",
    "axs[0].fill_between(integer_index, basal_active_low_50, basal_active_high_50, color='red', alpha=0.6)\n",
    "axs[0].fill_between(integer_index, basal_active_low_75, basal_active_high_75, color='red', alpha=0.4)\n",
    "axs[0].fill_between(integer_index, basal_active_low_95, basal_active_high_95, color='red', alpha=0.2)\n",
    "\n",
    "# Plot the median line\n",
    "axs[0].plot(integer_index, basal_active_median, linewidth=5, label='Posterior median', color='black')\n",
    "# axs[0].axvline(x=train_size * data_resolution, color='r', linestyle='-', label='Train/Test Split')\n",
    "# axs[0].axvline(x=(train_size + horizon) * data_resolution, color='g', linestyle='-', label='Prediction Horizon')\n",
    "\n",
    "# Add legend to the plot\n",
    "axs[0].legend()\n",
    "axs[0].set_xlim(0, 1440)\n",
    "axs[0].set_title('Endogenous Glucose Production')\n",
    "axs[0].set_xlabel('Time (minutes)')\n",
    "axs[0].set_ylabel('Glucose exursion (mmol/L)')\n",
    "\n",
    "# --------------------------------------------\n",
    "# Calculate the median and percentiles\n",
    "basal_active_median = np.median(basal_active_values, axis=(0, 1)) - np.median(trace.posterior['basal_baseline'].values, axis=(0, 1))\n",
    "basal_active_low_50, basal_active_high_50 = np.percentile(basal_active_values, [25, 75], axis=(0, 1)) - np.median(trace.posterior['basal_baseline'].values, axis=(0, 1))\n",
    "basal_active_low_75, basal_active_high_75 = np.percentile(basal_active_values, [12.5, 87.5], axis=(0, 1)) - np.median(trace.posterior['basal_baseline'].values, axis=(0, 1))\n",
    "basal_active_low_95, basal_active_high_95 = np.percentile(basal_active_values, [2.5, 97.5], axis=(0, 1)) - np.median(trace.posterior['basal_baseline'].values, axis=(0, 1))\n",
    "\n",
    "# Plot the median and percentiles\n",
    "axs[1].fill_between(integer_index, basal_active_low_50, basal_active_high_50, color='red', alpha=0.6)\n",
    "axs[1].fill_between(integer_index, basal_active_low_75, basal_active_high_75, color='red', alpha=0.4)\n",
    "axs[1].fill_between(integer_index, basal_active_low_95, basal_active_high_95, color='red', alpha=0.2)\n",
    "\n",
    "# Plot the median line\n",
    "axs[1].plot(integer_index, basal_active_median, linewidth=5, label='Posterior median', color='black')\n",
    "# axs[1].axvline(x=train_size * data_resolution, color='r', linestyle='-', label='Train/Test Split')\n",
    "# axs[1].axvline(x=(train_size + horizon) * data_resolution, color='g', linestyle='-', label='Prediction Horizon')\n",
    "\n",
    "# Add legend to the plot\n",
    "axs[1].legend(loc='lower center')\n",
    "axs[1].set_xlim(0, 1440)\n",
    "axs[1].set_title('Circadian addition')\n",
    "axs[1].set_xlabel('Time (minutes)')\n",
    "axs[1].set_ylabel('Glucose exursion (mmol/L)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1066d2",
   "metadata": {},
   "source": [
    "## Basal baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa358a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.kdeplot(np.median(trace.posterior['basal_baseline'].values, axis=0), label='Basal baseline', color='purple', linewidth=2)\n",
    "\n",
    "plt.title('Endogenous Glucose Baseline')\n",
    "plt.xlabel('mmol/L')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ebcc7",
   "metadata": {},
   "source": [
    "## Calories per unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533afc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.kdeplot(np.median(trace.posterior['calorie_insulin_ratio'].values, axis=0), label='Basal baseline', color='purple', linewidth=2)\n",
    "\n",
    "plt.title('Calories to insulin ratio')\n",
    "plt.xlabel('cal/U')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d062cc",
   "metadata": {},
   "source": [
    "## Macronutrient composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87adce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Define priors\n",
    "prior_means = [0.442, 0.147, 0.365]  # Mean values for carbs, protein, fat\n",
    "prior_stds = [0.075, 0.04, 0.064]  # Standard deviations for carbs, protein, fat\n",
    "colors = ['purple', 'green', 'orange']  # Colors for carbs, protein, fat\n",
    "labels = ['Carb', 'Protein', 'Fat']  # Labels for carbs, protein, fat\n",
    "\n",
    "# Define range of values\n",
    "x = np.linspace(0, 1, 1000)\n",
    "\n",
    "# Initialize figure\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Posterior and Prior Macro Composition Percentages')\n",
    "\n",
    "# Loop through macros\n",
    "for i in range(3):\n",
    "    # Draw prior\n",
    "    prior = norm.pdf(x, prior_means[i], prior_stds[i])\n",
    "    plt.fill_between(x, prior, color=colors[i], alpha=0.2)\n",
    "\n",
    "    # Draw posterior\n",
    "    posterior_samples = np.median(trace.posterior[f'logit_{labels[i][0]}'].values, axis=(0))\n",
    "    sns.kdeplot(posterior_samples, label=labels[i], color=colors[i], linewidth=0, fill=True, alpha=0.7)\n",
    "#     plt.hist(posterior_samples, bins=35, alpha=0.5, label=None, density=True, color=colors[i], edgecolor=None)\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel('Percentage')\n",
    "plt.xlim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e401d9d",
   "metadata": {},
   "source": [
    "## Plotting a Fourier series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa55126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "def fourier_series_np(time, n_terms, amplitude, phase_shift, data_resolution, period=1440):\n",
    "    time_adjusted = time * data_resolution  # make the time periodical over 1440 minutes\n",
    "    result = 0\n",
    "    for i in range(n_terms):\n",
    "        result += amplitude[i] * (np.sin(2 * np.pi * ((i+1) * (time_adjusted + phase_shift[i]) % period) / period) + 1) / 2\n",
    "    return result\n",
    "\n",
    "\n",
    "def plot_fourier_series(trace, variable_name, n_terms):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "    # Extract amplitude and phase_shift values\n",
    "    amplitude_values = trace.posterior[variable_name + '_amplitude'].values\n",
    "    phase_shift_values = trace.posterior[variable_name + '_phase_shift'].values\n",
    "\n",
    "    # Prepare an empty array to hold the Fourier series results for each term\n",
    "    fourier_series_results = np.empty((amplitude_values.shape[0], amplitude_values.shape[1], extended_size))\n",
    "    fourier_series_results_terms = np.empty((n_terms, amplitude_values.shape[0], amplitude_values.shape[1], extended_size))\n",
    "    time = np.arange(extended_size)\n",
    "\n",
    "    # Calculate the Fourier series for each sample and each set of amplitude and phase shift values\n",
    "    for i in range(amplitude_values.shape[0]):\n",
    "        for j in range(amplitude_values.shape[1]):\n",
    "            fourier_series_results[i, j, :] = fourier_series_np(time, n_terms, amplitude_values[i, j, :], phase_shift_values[i, j, :], data_resolution)\n",
    "            \n",
    "    # Calculate the Fourier series for each term and each set of amplitude and phase shift values\n",
    "    for term in range(n_terms):\n",
    "        for i in range(amplitude_values.shape[0]):\n",
    "            for j in range(amplitude_values.shape[1]):\n",
    "                amplitude_term = np.zeros(n_terms)\n",
    "                amplitude_term[term] = amplitude_values[i, j, term]\n",
    "                fourier_series_results_terms[term, i, j, :] = fourier_series_np(time, n_terms, amplitude_term, phase_shift_values[i, j, :], data_resolution)\n",
    "\n",
    "    # Calculate the median and percentiles at each time step\n",
    "    fourier_series_median = np.median(fourier_series_results, axis=(0, 1))\n",
    "    fourier_series_low_50, fourier_series_high_50 = np.percentile(fourier_series_results, [25, 75], axis=(0, 1))\n",
    "    fourier_series_low_75, fourier_series_high_75 = np.percentile(fourier_series_results, [12.5, 87.5], axis=(0, 1))\n",
    "    fourier_series_low_95, fourier_series_high_95 = np.percentile(fourier_series_results, [2.5, 97.5], axis=(0, 1))\n",
    "\n",
    "    # Calculate the median and percentiles at each time step for each term\n",
    "    fourier_series_terms_median = np.median(fourier_series_results_terms, axis=(1, 2))\n",
    "    fourier_series_terms_low_50, fourier_series_terms_high_50 = np.percentile(fourier_series_results_terms, [25, 75], axis=(1, 2))\n",
    "    fourier_series_terms_low_75, fourier_series_terms_high_75 = np.percentile(fourier_series_results_terms, [12.5, 87.5], axis=(1, 2))\n",
    "    fourier_series_terms_low_95, fourier_series_terms_high_95 = np.percentile(fourier_series_results_terms, [2.5, 97.5], axis=(1, 2))\n",
    "\n",
    "    # Subplot for the full Fourier series\n",
    "    axs[0].plot(time * data_resolution, fourier_series_median, color='black', label='Median (full series)')\n",
    "    axs[0].fill_between(time * data_resolution, fourier_series_low_50, fourier_series_high_50, color='gray', alpha=0.4, label='50% CI (full series)')\n",
    "    axs[0].set_title('Meal probability (mp)')\n",
    "    axs[0].set_xlabel('Minutes in a day')\n",
    "    axs[0].set_ylabel('Probability')\n",
    "    axs[0].set_xlim(0, 1440)\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Subplot for the underlying terms\n",
    "    colors = ['blue', 'red', 'green', 'purple', 'orange', 'gray']  # Define colors for each term\n",
    "    i = 12\n",
    "    for term in range(n_terms):\n",
    "        axs[1].plot(time * data_resolution, fourier_series_terms_median[term, :], color=colors[term], label=f'Median (term {term+1})', linewidth=i)\n",
    "        i -= 2\n",
    "#         axs[1].fill_between(time * data_resolution, fourier_series_terms_low_50[term, :], fourier_series_terms_high_50[term, :], color=colors[term], alpha=0.2, label=f'50% CI (term {term+1})')\n",
    "    axs[1].set_title('Underlying terms')\n",
    "    axs[1].set_xlabel('Minutes in a day')\n",
    "    axs[1].set_ylabel('Probability')\n",
    "    axs[1].set_xlim(0, 1440)\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_fourier_series(trace, 'meal', 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95355cb",
   "metadata": {},
   "source": [
    "# Utility functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plotting_variables(trace):\n",
    "    # Define dictionaries to hold results\n",
    "    plot_dict_glucose = {}\n",
    "    \n",
    "    # Extracting values from the trace\n",
    "    total_active = trace.posterior[\"total_active\"].values\n",
    "    total_passive = trace.posterior[\"total_passive\"].values\n",
    "\n",
    "    # Calculate the mean of sigma_samples along the first two dimensions\n",
    "    sigma_samples = trace.posterior['sigma'].values\n",
    "    mean_sigma_samples = np.mean(sigma_samples, axis=(0, 1))\n",
    "\n",
    "    # Generate noise with shape matching total_active (and total_passive)\n",
    "    noise = np.random.normal(loc=0, scale=mean_sigma_samples, size=total_active.shape)\n",
    "\n",
    "    # Add all components together\n",
    "    net = total_active + total_passive + noise\n",
    "\n",
    "    # Calculating percentiles\n",
    "    plot_dict_glucose['median'] = np.median(net, axis=(0, 1))\n",
    "    plot_dict_glucose['low_50'], plot_dict_glucose['high_50'] = np.percentile(net, [25, 75], axis=0)\n",
    "    plot_dict_glucose['low_75'], plot_dict_glucose['high_75'] = np.percentile(net, [12.5, 87.5], axis=0)\n",
    "    plot_dict_glucose['low_95'], plot_dict_glucose['high_95'] = np.percentile(net, [2.5, 97.5], axis=0)\n",
    "\n",
    "    return plot_dict_glucose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190bc1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_return_trace(cgm_train, bolus_train, basal_norm_15min, train_size, extended_size):\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "    #                        CONVOLUTION                      # \n",
    "    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "\n",
    "    def conv_activation(units, kernel):\n",
    "        \"\"\"\n",
    "        Perform the convolution using theano.tensor.nnet.conv2d.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        units : NDArray[np.float32]\n",
    "                number of units of insulin to counter effect, based on the g/U ratio\n",
    "        kernel : NDArray[np.float32]\n",
    "                 kernel representing the activation function\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        conv_result : NDArray[np.float32]\n",
    "                      result of the convolution\n",
    "        \"\"\"\n",
    "        # Reshape units and kernel tensors to meet the input requirements of conv2d\n",
    "        units = units.dimshuffle('x', 'x', 0, 'x')\n",
    "        kernel = kernel.dimshuffle('x', 'x', 0, 'x')\n",
    "\n",
    "        # Perform convolution\n",
    "        conv_result = nnet.conv2d(input=units, filters=kernel, border_mode='full')[0, 0, :, 0]\n",
    "        \n",
    "#         For pip:\n",
    "#         conv_result = pytensor.tensor.conv.conv2d(input=units, filters=kernel, border_mode='full')[0, 0, :, 0]\n",
    "\n",
    "        return conv_result\n",
    "\n",
    "\n",
    "    def fourier_series(time, n_terms, amplitude, phase_shift, data_resolution, period=1440):\n",
    "        time_adjusted = time * data_resolution  # make the time periodical over 1440 minutes\n",
    "        result = 0\n",
    "        for i in range(n_terms):\n",
    "            result += amplitude[i] * (tt.sin(2 * np.pi * ((i+1) * (time_adjusted + phase_shift[i]) % period) / period) + 1) / 2\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        # --------------- MEAL TIMING --------------------\n",
    "\n",
    "        # Meal availability fourier series\n",
    "        n_meal_terms = 1\n",
    "        meal_amplitude = pm.Uniform('meal_amplitude', lower=0, upper=1, shape=n_meal_terms)\n",
    "        meal_phase_shift = pm.Uniform('meal_phase_shift', lower=0, upper=1440, shape=n_meal_terms)\n",
    "        meal_prob = pm.Deterministic('mp', fourier_series(np.arange(extended_size), n_meal_terms, meal_amplitude, meal_phase_shift, data_resolution))\n",
    "        mt = pm.Bernoulli('mt', p=meal_prob, shape=extended_size)\n",
    "\n",
    "\n",
    "        # --------------- MEAL SIZE --------------------\n",
    "\n",
    "        # Carb, protein, and fat grams per meal\n",
    "        n_cpm_terms = 4  # Number of sinusoids for cpm\n",
    "        cpm_amplitude = pm.Uniform('cpm_amplitude', lower=0, upper=100, shape=n_cpm_terms)  # assuming max meal size of 100 calories\n",
    "        cpm_phase_shift = pm.Uniform('cpm_phase_shift', lower=0, upper=1440, shape=n_cpm_terms)\n",
    "        cpm = pm.Deterministic('cpm', fourier_series(np.arange(extended_size), n_cpm_terms, cpm_amplitude, cpm_phase_shift, data_resolution))\n",
    "\n",
    "        # Multiply the cpm values with mt\n",
    "        cpm_binary = pm.Deterministic('cpmt', tt.switch(tt.eq(mt, 1), cpm, 0))\n",
    "\n",
    "\n",
    "        # --------------- DIET COMPOSITION --------------------\n",
    "\n",
    "        # Diet composition percentage logits\n",
    "        logit_c = pm.Normal('logit_C', mu=0.442, sd=0.075)\n",
    "        logit_p = pm.Normal('logit_P', mu=0.147, sd=0.04)\n",
    "        logit_f = pm.Normal('logit_F', mu=0.365, sd=0.064)\n",
    "\n",
    "        # Apply softmax to obtain percentages summed to 1\n",
    "        softmax_logits = tt.nnet.softmax([logit_c, logit_p, logit_f])\n",
    "\n",
    "        # Percentages\n",
    "        perc_c = pm.Deterministic('%C', softmax_logits[0, 0])\n",
    "        perc_p = pm.Deterministic('%P', softmax_logits[0, 1])\n",
    "        perc_f = pm.Deterministic('%F', softmax_logits[0, 2])\n",
    "\n",
    "        # Diet composition in grams per meal\n",
    "        g_c = pm.Deterministic('g_C', cpm_binary * perc_c / calorie_per_gram_per_macro['carb'])\n",
    "        g_p = pm.Deterministic('g_P', cpm_binary * perc_p / calorie_per_gram_per_macro['protein'])\n",
    "        g_f = pm.Deterministic('g_F', cpm_binary * perc_f / calorie_per_gram_per_macro['fat'])\n",
    "\n",
    "        # Insulin required for each macronutrient (g/U)\n",
    "        ic = pm.Deterministic('IC', g_c / ic_ratio)\n",
    "        ip = pm.Deterministic('IP', g_p / ip_ratio)\n",
    "        if_ = pm.Deterministic('IF', g_f / if_ratio)\n",
    "\n",
    "\n",
    "        # --------------- POSITIVE CONVOLUTION --------------------\n",
    "\n",
    "        # Adjust the activation kernels to have a unit equal to 1\n",
    "        carb_kernel = theano_carbohydrate_activation(1, conversion_rate=conversion_ratios['carb'])[::data_resolution]\n",
    "        protein_kernel = theano_protein_activation(1, conversion_rate=conversion_ratios['protein'])[::data_resolution]\n",
    "        fat_kernel = theano_fat_activation(1, conversion_rate=conversion_ratios['fat'])[::data_resolution]\n",
    "\n",
    "        # Convert mt to float to be able to convolute\n",
    "        mt = mt.astype('float64')\n",
    "\n",
    "        # Convolution of meal availability with activation functions\n",
    "        conv_carb = pm.Deterministic('conv_carb', conv_activation(ic, carb_kernel))\n",
    "        conv_protein = pm.Deterministic('conv_protein', conv_activation(ip, protein_kernel))\n",
    "        conv_fat = pm.Deterministic('conv_fat', conv_activation(if_, fat_kernel))\n",
    "\n",
    "        # Total blood glucose level contribution from all macronutrients\n",
    "        total_activation = pm.Deterministic('total_activation', conv_carb + conv_protein + conv_fat)\n",
    "\n",
    "        # -------------------- NEGATIVE CONVOLUTION --------------------\n",
    "\n",
    "        # Meal availability fourier series\n",
    "        n_insulin_terms = 3\n",
    "        insulin_amplitude = pm.Uniform('insulin_amplitude', lower=0, upper=0.3, shape=n_insulin_terms)\n",
    "        insulin_phase_shift = pm.Uniform('insulin_phase_shift', lower=0, upper=1440, shape=n_insulin_terms)\n",
    "        insulin_prob = pm.Deterministic('ip', fourier_series(np.arange(extended_size), n_insulin_terms, insulin_amplitude, insulin_phase_shift, data_resolution))\n",
    "        it = pm.Bernoulli('it', p=insulin_prob, shape=extended_size)\n",
    "\n",
    "        # Calories to units of insulin ratio\n",
    "        calorie_insulin_ratio = pm.HalfNormal('calorie_insulin_ratio', tau=1/14)\n",
    "\n",
    "        upm = pm.Deterministic('upm', cpm / calorie_insulin_ratio)\n",
    "\n",
    "        # Multiply the cpm values with mt\n",
    "        insulin_binary = pm.Deterministic('upmt', tt.switch(tt.eq(it, 1), upm, 0))\n",
    "\n",
    "        # Create kernel\n",
    "        insulin_kernel = theano_insulin_activation(1)[::data_resolution]\n",
    "        bolus_insulin_conv = pm.Deterministic('conv_insulin', conv_activation(insulin_binary, insulin_kernel))\n",
    "\n",
    "        insulin_sd = pm.Exponential('insulin_sigma', lam=1/0.5)\n",
    "        bolus_insulin = pm.Normal('bolus_insulin', mu=bolus_insulin_conv[:train_size], sd=insulin_sd, observed=bolus_train)\n",
    "\n",
    "        # --------------- PASSIVE COMPONENT --------------------\n",
    "\n",
    "        # Basal glucose production\n",
    "        n_basal_terms = 1\n",
    "        basal_amplitude = pm.Uniform('basal_amplitude', lower=0, upper=1, shape=n_basal_terms)\n",
    "        basal_phase_shift = pm.Uniform('basal_phase_shift', lower=0, upper=1440, shape=n_basal_terms)\n",
    "\n",
    "        basal_offset = pm.Normal('basal_baseline', mu=3, sd=1)\n",
    "        basal_active = pm.Deterministic('basal_active', fourier_series(np.arange(extended_size), n_basal_terms, basal_amplitude, basal_phase_shift, data_resolution) + basal_offset)    \n",
    "        total_basal = pm.Data('total_basal', basal_norm_15min[:extended_size])\n",
    "\n",
    "        # --------------- COMBINING VARIABLES ---------------\n",
    "\n",
    "        # Calculate component effects\n",
    "        total_active = pm.Deterministic('total_active', total_activation[:extended_size] - bolus_insulin_conv[:extended_size])  # Total active component\n",
    "        total_passive = pm.Deterministic('total_passive', basal_active - total_basal)  # Total passive component\n",
    "\n",
    "        # Theoretical CGM readings\n",
    "        total_cgm = pm.Deterministic('cgm_est', total_active[:train_size] + total_passive[:train_size])\n",
    "\n",
    "        # Define the likelihood of the model\n",
    "        sigma = pm.Exponential('sigma', lam=1/0.5)\n",
    "        likelihood = pm.Normal('likelihood', mu=total_cgm, sd=sigma, observed=cgm_train)\n",
    "\n",
    "        # --------------- SAMPLING ---------------\n",
    "\n",
    "        # Run the MCMC sampling\n",
    "        step = pm.NUTS(target_accept=0.95)\n",
    "        trace = pm.sample(draws=2000, tune=1000, chains=4, cores=4, step=step, return_inferencedata=True)\n",
    "    \n",
    "    return trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e21ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define hypoglycemia threshold\n",
    "threshold = 70 / 18.0182\n",
    "\n",
    "# Define function to generate binary hypoglycemia series\n",
    "def generate_hypoglycemia_series(data, threshold):\n",
    "    data = np.array(data)  # Convert data to a numpy array\n",
    "    hypoglycemia_series = (data < threshold).astype(int)\n",
    "    return hypoglycemia_series\n",
    "\n",
    "def evaluate(test_data, pred_array):\n",
    "    # ---- RMSE --------\n",
    "    mse = mean_squared_error(test_data, pred_array)\n",
    "    rmse = sqrt(mse)\n",
    "    print('RMSE: {}'.format(round(rmse * 18.0182, 2)))  # Multiply by 18.0182 to convert from mmol/L to mg/dL\n",
    "\n",
    "    # ---- MCC --------\n",
    "    # Generate binary actual and predicted hypoglycemia series\n",
    "    actual_hypoglycemia_series = generate_hypoglycemia_series(test_data, threshold)\n",
    "    predicted_hypoglycemia_series = generate_hypoglycemia_series(pred_array, threshold)\n",
    "\n",
    "    # Compute TP, FP, FN, and TN\n",
    "    TP = np.sum((predicted_hypoglycemia_series == 1) & (actual_hypoglycemia_series == 1))\n",
    "    FP = np.sum((predicted_hypoglycemia_series == 1) & (actual_hypoglycemia_series == 0))\n",
    "    FN = np.sum((predicted_hypoglycemia_series == 0) & (actual_hypoglycemia_series == 1))\n",
    "    TN = np.sum((predicted_hypoglycemia_series == 0) & (actual_hypoglycemia_series == 0))\n",
    "\n",
    "    # Compute MCC\n",
    "    mcc = (TP * TN - FP * FN) / (np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) + 1e-10)\n",
    "\n",
    "    return round(rmse * 18.0182, 2), mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9cad4",
   "metadata": {},
   "source": [
    "# Iterative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_minutes =  1790\n",
    "\n",
    "# Define result storing arrays\n",
    "glucose_median_pred = [[] for i in range(horizon_minutes // data_resolution)]\n",
    "glucose_low_50_pred, glucose_high_50_pred = [[] for i in range(horizon_minutes // data_resolution)], [[] for i in range(horizon_minutes // data_resolution)]\n",
    "glucose_low_75_pred, glucose_high_75_pred = [[] for i in range(horizon_minutes // data_resolution)], [[] for i in range(horizon_minutes // data_resolution)]\n",
    "glucose_low_95_pred, glucose_high_95_pred = [[] for i in range(horizon_minutes // data_resolution)], [[] for i in range(horizon_minutes // data_resolution)]\n",
    "\n",
    "# # These will be calculated afterwards\n",
    "# rmse_median, rmse_lower, rmse_higher = [[[] for _ in cgm_test.values] for _ in look_ahead_intervals], [[[] for _ in cgm_test.values] for _ in look_ahead_intervals], [[[] for _ in cgm_test.values] for _ in look_ahead_intervals]\n",
    "# mcc_median, mcc_lower, mcc_higher = [[[] for _ in cgm_test.values] for _ in look_ahead_intervals], [[[] for _ in cgm_test.values] for _ in look_ahead_intervals], [[[] for _ in cgm_test.values] for _ in look_ahead_intervals]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca7ba0",
   "metadata": {},
   "source": [
    "### Intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while horizon_minutes > 0:\n",
    "    print(\"Running length\", horizon_minutes)\n",
    "\n",
    "   # ----------------- CREATE VARIABLES -----------------\n",
    "    # Define the horizon length\n",
    "    horizon = int(horizon_minutes / data_resolution)  # Adjust for data resolution\n",
    "\n",
    "    # Extend the time series for the horizon\n",
    "    train_size = len(insulin_norm_15min) - horizon\n",
    "    test_size = horizon\n",
    "    extended_size = train_size + horizon\n",
    "\n",
    "    # Define training and testing variables\n",
    "    cgm_train = cgm_norm_15min[:train_size]\n",
    "    cgm_test = cgm_norm_15min[train_size:]\n",
    "    bolus_train = bolus_norm_15min[:train_size]\n",
    "    bolus_test = bolus_norm_15min[train_size:]    \n",
    "    \n",
    "    # ----------------- RUN MODEL  -----------------\n",
    "    trace = fit_and_return_trace(cgm_train, bolus_train, basal_norm_15min, train_size, extended_size)\n",
    "\n",
    "    # ------------ CALCULATE USEFUL VARIABLES  -----------\n",
    "    plot_dict_glucose = get_plotting_variables(trace)\n",
    "    \n",
    "    # ------------ EVALUATE AND STORE  -----------    \n",
    "    print(plot_dict_glucose['median'][train_size:])\n",
    "    print(cgm_test.values)\n",
    "        \n",
    "    glucose_median_pred[i].append(plot_dict_glucose['median'][train_size:])\n",
    "    glucose_low_50_pred[i].append(np.median(plot_dict_glucose['low_50'], axis=0)[train_size:])\n",
    "    glucose_high_50_pred[i].append(np.median(plot_dict_glucose['high_50'], axis=0)[train_size:])\n",
    "    glucose_low_75_pred[i].append(np.median(plot_dict_glucose['low_75'], axis=0)[train_size:])\n",
    "    glucose_high_75_pred[i].append(np.median(plot_dict_glucose['high_75'], axis=0)[train_size:])\n",
    "    glucose_low_95_pred[i].append(np.median(plot_dict_glucose['low_95'], axis=0)[train_size:])\n",
    "    glucose_high_95_pred[i].append(np.median(plot_dict_glucose['high_95'], axis=0)[train_size:])\n",
    "    \n",
    "    # ------------ INTERMEDIATE SAVE  -----------   \n",
    "    # Create DataFrame from the prediction lists with train_size as the index\n",
    "    df_median_pred = pd.DataFrame([plot_dict_glucose['median'][train_size:]], index=[train_size])\n",
    "    df_low_50_pred = pd.DataFrame([np.median(plot_dict_glucose['low_50'], axis=0)[train_size:]], index=[train_size])\n",
    "    df_high_50_pred = pd.DataFrame([np.median(plot_dict_glucose['high_50'], axis=0)[train_size:]], index=[train_size])\n",
    "    df_low_75_pred = pd.DataFrame([np.median(plot_dict_glucose['low_75'], axis=0)[train_size:]], index=[train_size])\n",
    "    df_high_75_pred = pd.DataFrame([np.median(plot_dict_glucose['high_75'], axis=0)[train_size:]], index=[train_size])\n",
    "    df_low_95_pred = pd.DataFrame([np.median(plot_dict_glucose['low_95'], axis=0)[train_size:]], index=[train_size])\n",
    "    df_high_95_pred = pd.DataFrame([np.median(plot_dict_glucose['high_95'], axis=0)[train_size:]], index=[train_size])\n",
    "    \n",
    "    # Save DataFrame to CSV, append if file already exists\n",
    "    with open('glucose_median_pred6.csv', 'a') as f:\n",
    "        df_median_pred.to_csv(f, header=False)\n",
    "    with open('glucose_low_50_pred6.csv', 'a') as f:\n",
    "        df_low_50_pred.to_csv(f, header=False)\n",
    "    with open('glucose_high_50_pred6.csv', 'a') as f:\n",
    "        df_high_50_pred.to_csv(f, header=False)\n",
    "    with open('glucose_low_75_pred6.csv', 'a') as f:\n",
    "        df_low_75_pred.to_csv(f, header=False)\n",
    "    with open('glucose_high_75_pred6.csv', 'a') as f:\n",
    "        df_high_75_pred.to_csv(f, header=False)\n",
    "    with open('glucose_low_95_pred6.csv', 'a') as f:\n",
    "        df_low_95_pred.to_csv(f, header=False)\n",
    "    with open('glucose_high_95_pred6.csv', 'a') as f:\n",
    "        df_high_95_pred.to_csv(f, header=False)\n",
    "\n",
    "    horizon_minutes -= data_resolution\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d48e1",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff3515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed \n",
    "horizon_minutes =  1790\n",
    "horizon = int(horizon_minutes / data_resolution)  # Adjust for data resolution\n",
    "\n",
    "# Extend the time series for the horizon\n",
    "train_size = len(insulin_norm_15min) - horizon\n",
    "test_size = horizon\n",
    "extended_size = train_size + horizon\n",
    "\n",
    "# Define training and testing variables\n",
    "cgm_train = cgm_norm_15min[:train_size]\n",
    "cgm_test = cgm_norm_15min[train_size:]\n",
    "bolus_train = bolus_norm_15min[:train_size]\n",
    "bolus_test = bolus_norm_15min[train_size:]   \n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "observed_glucose = cgm_test.values\n",
    "observations_glucose = [np.arange(i, len(observed_glucose)) for i in range(len(observed_glucose))]\n",
    "\n",
    "print(len(predictions_glucose_median))\n",
    "\n",
    "# Extract median, highs, and lows\n",
    "predictions_glucose_median = [sublist[0] for sublist in glucose_median_pred]\n",
    "predictions_glucose_low_50 = [sublist[0] for sublist in glucose_low_50_pred]\n",
    "predictions_glucose_high_50 = [sublist[0] for sublist in glucose_high_50_pred]\n",
    "predictions_glucose_low_75 = [sublist[0] for sublist in glucose_low_75_pred]\n",
    "predictions_glucose_high_75 = [sublist[0] for sublist in glucose_high_75_pred]\n",
    "predictions_glucose_low_95 = [sublist[0] for sublist in glucose_low_95_pred]\n",
    "predictions_glucose_high_95 = [sublist[0] for sublist in glucose_high_95_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb174dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nth_element(n, list_of_arrays):\n",
    "    nth_elements = []\n",
    "    for arr in list_of_arrays:\n",
    "        try:\n",
    "            nth_elements.append(arr[n])\n",
    "        except IndexError:\n",
    "            nth_elements.append(None)\n",
    "    return nth_elements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20564b8",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152785ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "# Observed \n",
    "horizon_minutes = 1790 # 3780 # 2000  # 700\n",
    "horizon = int(horizon_minutes / data_resolution)  # Adjust for your data resolution\n",
    "\n",
    "# Extend the time series for the horizon\n",
    "train_size = len(insulin_norm_15min) - horizon \n",
    "test_size = horizon\n",
    "\n",
    "extended_size = train_size + horizon\n",
    "integer_index = np.arange(extended_size) * data_resolution\n",
    "\n",
    "# Define training and testing variables\n",
    "cgm_train = cgm_norm_15min[:train_size]\n",
    "cgm_test = cgm_norm_15min[train_size:]\n",
    "bolus_train = bolus_norm_15min[:train_size]\n",
    "bolus_test = bolus_norm_15min[train_size:]\n",
    "\n",
    "print(cgm_test[-2], cgm_test[-1])\n",
    "\n",
    "\n",
    "integer_index = np.arange(len(observed_glucose))  * data_resolution\n",
    "\n",
    "# First, get a boolean mask where True indicates a NaN value in cgm_train\n",
    "nan_mask = np.isnan(cgm_train)\n",
    "\n",
    "# Then, replace NaNs in cgm_train with corresponding net_median values\n",
    "cgm_train[nan_mask] = net_median[:train_size][nan_mask]\n",
    "\n",
    "\n",
    "test_data = cgm_test\n",
    "start = len(cgm_train)\n",
    "end = start + horizon_minutes - 1\n",
    "\n",
    "print(start, end)\n",
    "\n",
    "# AR Model, we do not give it a exogenous variable, since this requires future values for insulin to be able to forecast. \n",
    "# # However this is not realistic.\n",
    "ar_model = AutoReg(cgm_train, lags=1, seasonal=True, trend='t', period=1440//data_resolution)\n",
    "ar_model_fit = ar_model.fit()\n",
    "glucose_pred_ar = ar_model_fit.predict(start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cff1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(20, 7))\n",
    "\n",
    "\n",
    "ax1.set_xlabel('time')\n",
    "ax1.set_ylabel('CGM')\n",
    "ax1.plot(cgm_train, color='green', linewidth=5, label='Observed')\n",
    "ax1.plot(cgm_test, color='lightgreen', label='True', linewidth=5)\n",
    "ax1.plot(glucose_pred_ar, color='blue', label='Predicted', linewidth=5)\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.axvline(x=max(cgm_train.index), color='red', linewidth=5, label='Fit split')\n",
    "\n",
    "# instantiate a second axes that shares the same x-axis\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Count of NaNs', color=color)  \n",
    "n, bins, patches = ax2.hist(nan_indices, bins=50, alpha=0.3, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Day lines\n",
    "for i in range(0, len(series.index)):\n",
    "    if series.index[i].hour == 0 and series.index[i].minute == 0:\n",
    "        ax1.axvline(x=series.index[i], color='grey', linestyle='--')\n",
    "\n",
    "ax1.set_xlim(min(cgm_train.index), max(cgm_test.index))\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "ax1.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "look_ahead_intervals = [30, 60, 90, 120]  # Define the look ahead intervals\n",
    "\n",
    "# Arrays to store predictions for each interval\n",
    "predictions_arrays = [np.zeros(len(test_data)) for _ in look_ahead_intervals]\n",
    "\n",
    "# Sliding window predictions\n",
    "for t in range(len(test_data)):\n",
    "    # Updating the train_data with the latest known value\n",
    "    train_data = cgm_norm_15min[:train_size+t]\n",
    "    train_data = train_data.fillna(0)\n",
    "    \n",
    "    for i, interval in enumerate(look_ahead_intervals):\n",
    "        # Define the end point for the interval\n",
    "        end_point = interval // data_resolution  # Convert minutes to steps\n",
    "        \n",
    "        # If there's not enough future data to predict, break the loop\n",
    "        if t + end_point >= len(test_data):\n",
    "            break\n",
    "        \n",
    "        # Define prediction horizon\n",
    "        start = len(train_data)\n",
    "        end = start + end_point - 1\n",
    "\n",
    "        # AR Model\n",
    "        arx_model = AutoReg(train_data, lags=1, seasonal=True, trend='t', period=1440//data_resolution)\n",
    "        arx_model_fit = arx_model.fit()\n",
    "        glucose_pred_arx = arx_model_fit.predict(start=start, end=end)\n",
    "        \n",
    "        # Store the prediction\n",
    "        predictions_arrays[i][t + end_point] = glucose_pred_arx.iloc[-1]\n",
    "        \n",
    "    # Print progress\n",
    "    if t % 10 == 0:\n",
    "        print('Predicted up to point:', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe67fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(test_data.index, test_data.values, label='Test Data', linewidth=5)\n",
    "\n",
    "for i, interval in enumerate(look_ahead_intervals):\n",
    "    plt.plot(test_data.index, predictions_arrays[i], label='Predictions {} min ahead'.format(interval))\n",
    "\n",
    "plt.title('Blood Glucose Level Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Glucose Level')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# RMSE calculations\n",
    "for i, interval in enumerate(look_ahead_intervals):\n",
    "    actual_values = test_data[:len(predictions_arrays[i])]\n",
    "    predicted_values = predictions_arrays[i][:len(test_data)]\n",
    "    \n",
    "    mse = mean_squared_error(actual_values, predicted_values)\n",
    "    rmse = sqrt(mse)\n",
    "    print('RMSE for the look ahead of {} minutes: {}'.format(interval, round(rmse * 18.0182, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153cab13",
   "metadata": {},
   "source": [
    "# Final plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style and color palette\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "integer_index = np.arange(len(observed_glucose))  * data_resolution\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(15,8))  # Optional: set the figure size\n",
    "\n",
    "# Plot the observed glucose\n",
    "plt.plot(integer_index, observed_glucose, label='Observed Glucose', color='green', alpha=1, linewidth=8, zorder=10)\n",
    "\n",
    "# Plot our predictions\n",
    "plt.plot(predicted_range * data_resolution, predicted, linewidth=5, color='black', linestyle='-', label='Our Predictions')\n",
    "\n",
    "# Plot AR model\n",
    "plt.plot(integer_index[4:], predictions_arrays[3][4:], color='blue', linewidth=5, alpha=0.6, label='AR Predictions')\n",
    "\n",
    "# Plot the prediction intervals\n",
    "plt.fill_between(predicted_range * data_resolution, predicted_low_50, predicted_high_50, color='red', alpha=0.6)\n",
    "plt.fill_between(predicted_range * data_resolution, predicted_low_75, predicted_high_75, color='red', alpha=0.4)\n",
    "plt.fill_between(predicted_range * data_resolution, predicted_low_95, predicted_high_95, color='red', alpha=0.2)\n",
    "\n",
    "# Lines and patches\n",
    "plt.fill_between(integer_index, 3, 10, color='lightgreen', alpha=0.3, zorder=-10)\n",
    "\n",
    "# Format the plot\n",
    "plt.title(f'Glucose Predictions ({ph_minutes} min PH)', fontsize=25)\n",
    "\n",
    "\n",
    "plt.axvline(x=350, color='black', linestyle='--', zorder=10, linewidth=2)\n",
    "plt.axvline(x=1790, color='black', linestyle='--', zorder=10, linewidth=2)\n",
    "\n",
    "\n",
    "plt.xlabel('Time', fontsize=18)\n",
    "plt.ylabel('mmol/L', fontsize=18)\n",
    "plt.ylim(2.5, 12.5)\n",
    "\n",
    "plt.legend(fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260dfa9a",
   "metadata": {},
   "source": [
    "# Getting the saved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da376071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Median\n",
    "predictions_glucose_median_df = pd.read_csv('glucose_median_pred6.csv', header=None, index_col=0)\n",
    "glucose_median_pred = [row.dropna().tolist() for index, row in predictions_glucose_median_df.iterrows()]\n",
    "\n",
    "# Upper 95\n",
    "predictions_glucose_median_df = pd.read_csv('glucose_high_95_pred6.csv', header=None, index_col=0)\n",
    "glucose_high_95_pred = [row.dropna().tolist() for index, row in predictions_glucose_median_df.iterrows()]\n",
    "\n",
    "# Upper 75\n",
    "predictions_glucose_median_df = pd.read_csv('glucose_high_75_pred6.csv', header=None, index_col=0)\n",
    "glucose_high_75_pred = [row.dropna().tolist() for index, row in predictions_glucose_median_df.iterrows()]\n",
    "\n",
    "# Upper 50\n",
    "predictions_glucose_median_df = pd.read_csv('glucose_high_50_pred6.csv', header=None, index_col=0)\n",
    "glucose_high_50_pred = [row.dropna().tolist() for index, row in predictions_glucose_median_df.iterrows()]\n",
    "\n",
    "# Lower 95\n",
    "predictions_glucose_median_df = pd.read_csv('glucose_low_95_pred6.csv', header=None, index_col=0)\n",
    "glucose_low_95_pred = [row.dropna().tolist() for index, row in predictions_glucose_median_df.iterrows()]\n",
    "\n",
    "# Lower 75\n",
    "predictions_glucose_median_df = pd.read_csv('glucose_low_75_pred6.csv', header=None, index_col=0)\n",
    "glucose_low_75_pred = [row.dropna().tolist() for index, row in predictions_glucose_median_df.iterrows()]\n",
    "\n",
    "# Lower 50\n",
    "predictions_glucose_median_df = pd.read_csv('glucose_low_50_pred6.csv', header=None, index_col=0)\n",
    "glucose_low_50_pred = [row.dropna().tolist() for index, row in predictions_glucose_median_df.iterrows()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc08e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_glucose = cgm_test.values\n",
    "observations_glucose = [np.arange(i, len(observed_glucose)) for i in range(len(observed_glucose))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1096e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style and color palette\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10,6))  # Optional: set the figure size\n",
    "\n",
    "integer_index = np.arange(len(observed_glucose))  * data_resolution\n",
    "\n",
    "# Plot the observed glucose and predicted glucose\n",
    "plt.plot(integer_index, observed_glucose, label='Observed Glucose', color='green', alpha=1, linewidth=3, marker='x')\n",
    "\n",
    "# Plot the nth prediction\n",
    "ph_minutes = 120\n",
    "ph = (ph_minutes // data_resolution) - 1\n",
    "predicted = extract_nth_element(ph, predictions_glucose_median)[:len(integer_index) - ph]\n",
    "predicted_range = observations_glucose[ph]\n",
    "\n",
    "observed = observed_glucose[ph:]\n",
    "\n",
    "plt.plot(predicted_range * data_resolution, predicted, linewidth=2, color='red', linestyle='-', label=f'{ph_minutes} min PH', marker='x')\n",
    "\n",
    "# Extract values for 50%, 75% and 95% prediction intervals\n",
    "predicted_low_50 = extract_nth_element(ph, predictions_glucose_low_50)[:len(integer_index) - ph]\n",
    "predicted_high_50 = extract_nth_element(ph, predictions_glucose_high_50)[:len(integer_index) - ph]\n",
    "predicted_low_75 = extract_nth_element(ph, predictions_glucose_low_75)[:len(integer_index) - ph][:len(integer_index) - ph]\n",
    "predicted_high_75 = extract_nth_element(ph, predictions_glucose_high_75)[:len(integer_index) - ph]\n",
    "predicted_low_95 = extract_nth_element(ph, predictions_glucose_low_95)[:len(integer_index) - ph]\n",
    "predicted_high_95 = extract_nth_element(ph, predictions_glucose_high_95)[:len(integer_index) - ph]\n",
    "\n",
    "# Plot the prediction intervals\n",
    "plt.fill_between(predicted_range * data_resolution, predicted_low_50, predicted_high_50, color='red', alpha=0.1, label='50% Prediction Interval')\n",
    "plt.fill_between(predicted_range * data_resolution, predicted_low_75, predicted_high_75, color='red', alpha=0.2, label='75% Prediction Interval')\n",
    "plt.fill_between(predicted_range * data_resolution, predicted_low_95, predicted_high_95, color='red', alpha=0.3, label='95% Prediction Interval')\n",
    "\n",
    "\n",
    "# Lines and patches\n",
    "plt.fill_between(integer_index, 3, 10, color='lightgreen', alpha=0.2)\n",
    "\n",
    "# Format the plot\n",
    "plt.title('Glucose level over time with Predictions', fontsize=16)\n",
    "\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel('mmol/L', fontsize=14)\n",
    "plt.ylim(2, 13)\n",
    "# plt.xlim(0, 1440)\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19095c85",
   "metadata": {},
   "source": [
    "# Clarke error grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c07dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "def clarke_error_grid(ref_values, pred_values, title_string):\n",
    "\n",
    "    #Checking to see if the lengths of the reference and prediction arrays are the same\n",
    "    assert (len(ref_values) == len(pred_values)), \"Unequal number of values (reference : {}) (prediction : {}).\".format(len(ref_values), len(pred_values))\n",
    "\n",
    "    #Checks to see if the values are within the normal physiological range, otherwise it gives a warning\n",
    "    if max(ref_values) > 400 or max(pred_values) > 400:\n",
    "        print(\"Input Warning: the maximum reference value {} or the maximum prediction value {} exceeds the normal physiological range of glucose (<400 mg/dl).\").format(max(ref_values), max(pred_values))\n",
    "    if min(ref_values) < 0 or min(pred_values) < 0:\n",
    "        print(\"Input Warning: the minimum reference value {} or the minimum prediction value {} is less than 0 mg/dl.\").format(min(ref_values),  min(pred_values))\n",
    "\n",
    "    #Clear plot\n",
    "    plt.clf()\n",
    "\n",
    "    #Set up plot\n",
    "    plt.scatter(ref_values, pred_values, marker='o', color='darkblue', s=15, alpha=1)\n",
    "    plt.title(title_string + \" Clarke Error Grid\")\n",
    "    plt.xlabel(\"Reference Concentration (mg/dl)\")\n",
    "    plt.ylabel(\"Prediction Concentration (mg/dl)\")\n",
    "    plt.xticks([0, 50, 100, 150, 200, 250, 300, 350, 400])\n",
    "    plt.yticks([0, 50, 100, 150, 200, 250, 300, 350, 400])\n",
    "    plt.gca().set_facecolor('white')\n",
    "\n",
    "    #Set axes lengths\n",
    "    plt.gca().set_xlim([0, 400])\n",
    "    plt.gca().set_ylim([0, 400])\n",
    "    plt.gca().set_aspect((400)/(400))\n",
    "\n",
    "    #Plot zone lines\n",
    "    plt.plot([0,400], [0,400], ':', c='black')                      #Theoretical 45 regression line\n",
    "    plt.plot([0, 175/3], [70, 70], '-', c='black')\n",
    "    #plt.plot([175/3, 320], [70, 400], '-', c='black')\n",
    "    plt.plot([175/3, 400/1.2], [70, 400], '-', c='black')           #Replace 320 with 400/1.2 because 100*(400 - 400/1.2)/(400/1.2) =  20% error\n",
    "    plt.plot([70, 70], [84, 400],'-', c='black')\n",
    "    plt.plot([0, 70], [180, 180], '-', c='black')\n",
    "    plt.plot([70, 290],[180, 400],'-', c='black')\n",
    "    # plt.plot([70, 70], [0, 175/3], '-', c='black')\n",
    "    plt.plot([70, 70], [0, 56], '-', c='black')                     #Replace 175.3 with 56 because 100*abs(56-70)/70) = 20% error\n",
    "    # plt.plot([70, 400],[175/3, 320],'-', c='black')\n",
    "    plt.plot([70, 400], [56, 320],'-', c='black')\n",
    "    plt.plot([180, 180], [0, 70], '-', c='black')\n",
    "    plt.plot([180, 400], [70, 70], '-', c='black')\n",
    "    plt.plot([240, 240], [70, 180],'-', c='black')\n",
    "    plt.plot([240, 400], [180, 180], '-', c='black')\n",
    "    plt.plot([130, 180], [0, 70], '-', c='black')\n",
    "\n",
    "    #Add zone titles\n",
    "    plt.text(30, 15, \"A\", fontsize=15)\n",
    "    plt.text(370, 260, \"B\", fontsize=15)\n",
    "    plt.text(280, 370, \"B\", fontsize=15)\n",
    "    plt.text(160, 370, \"C\", fontsize=15)\n",
    "    plt.text(160, 15, \"C\", fontsize=15)\n",
    "    plt.text(30, 140, \"D\", fontsize=15)\n",
    "    plt.text(370, 120, \"D\", fontsize=15)\n",
    "    plt.text(30, 370, \"E\", fontsize=15)\n",
    "    plt.text(370, 15, \"E\", fontsize=15)\n",
    "\n",
    "    #Statistics from the data\n",
    "    zone = [0] * 5\n",
    "    for i in range(len(ref_values)):\n",
    "        if (ref_values[i] <= 70 and pred_values[i] <= 70) or (pred_values[i] <= 1.2*ref_values[i] and pred_values[i] >= 0.8*ref_values[i]):\n",
    "            zone[0] += 1    #Zone A\n",
    "\n",
    "        elif (ref_values[i] >= 180 and pred_values[i] <= 70) or (ref_values[i] <= 70 and pred_values[i] >= 180):\n",
    "            zone[4] += 1    #Zone E\n",
    "\n",
    "        elif ((ref_values[i] >= 70 and ref_values[i] <= 290) and pred_values[i] >= ref_values[i] + 110) or ((ref_values[i] >= 130 and ref_values[i] <= 180) and (pred_values[i] <= (7/5)*ref_values[i] - 182)):\n",
    "            zone[2] += 1    #Zone C\n",
    "        elif (ref_values[i] >= 240 and (pred_values[i] >= 70 and pred_values[i] <= 180)) or (ref_values[i] <= 175/3 and pred_values[i] <= 180 and pred_values[i] >= 70) or ((ref_values[i] >= 175/3 and ref_values[i] <= 70) and pred_values[i] >= (6/5)*ref_values[i]):\n",
    "            zone[3] += 1    #Zone D\n",
    "        else:\n",
    "            zone[1] += 1    #Zone B\n",
    "\n",
    "    return plt, zone\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "pltt, zone = clarke_error_grid(np.array(observed) * 18.0182, np.array(predicted) * 18.0182, \"Ours 120 min -\")\n",
    "total_points = sum(zone)\n",
    "percentage_zone = [round(z/total_points*100, 2) for z in zone]\n",
    "\n",
    "print(percentage_zone)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "pltt, zone = clarke_error_grid(np.array(observed[1:]) * 18.0182, np.array(predictions_arrays[3][4:]) * 18.0182, \"AR 120 min -\")\n",
    "total_points = sum(zone)\n",
    "percentage_zone = [round(z/total_points*100, 2) for z in zone]\n",
    "print(percentage_zone)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc3_env",
   "language": "python",
   "name": "pymc3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
